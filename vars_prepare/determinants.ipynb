{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#the code is to replicate the paper \"Annual report readability, current earnings,and earnings persistence\" by Feng Li, 2008\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Finally, firm-years that have operating earnings (scaled by book value of assets) greater than 1 or less than -1 are deleted from the sample. \n",
    "# 7. control variables calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#6. Finally, firm-years that have operating earnings (scaled by book value of assets) greater than 1 or less than -1 are deleted from the sample. \n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "conn = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_funda = conn.raw_sql(\"\"\"SELECT * \n",
    "                          FROM comp.funda\n",
    "                          WHERE datadate BETWEEN '2014-01-01' AND '2023-12-31'\"\"\")\n",
    "comp_funda.to_csv(\"comp_funda.csv\", index=False)\n",
    "#directly download the data from wrds would be much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/w05mrsdn0r9d85szm0g3kg740000gn/T/ipykernel_614/80131807.py:3: DtypeWarning: Columns (26,30,948,949,950,970,975) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  firm_annual = pd.read_csv(\"comp_funda.csv\")\n"
     ]
    }
   ],
   "source": [
    "firm_year = pd.read_csv('merge.csv' )\n",
    "firm_year['filing_date'] = pd.to_datetime(firm_year['filing_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "firm_annual = pd.read_csv(\"comp_funda.csv\")\n",
    "\n",
    "#left merge firm_year with firm_annual by datadate, gvkey, cik\n",
    "merge = pd.merge(firm_year, firm_annual, on=['datadate', 'gvkey', 'cik'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Earnings is operating earnings (data178 of Compustat: oiadp) scaled by book value of assets. at\n",
    "#Finally, firm-years that have operating earnings (scaled by book value of assets) greater than 1 or less than - 1 are deleted from the sample.\n",
    "#oiadp/at\n",
    "merge['Earnings'] = merge['oiadp'] / merge['at']\n",
    "merge = merge[(merge['Earnings'] <= 1) & (merge['Earnings'] >= -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data6 : at\n",
    "#data25 : csho\n",
    "#data181 : lt\n",
    "#data199 : prcc\n",
    "#data178: oiadp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market-to-book is the market value of the firm divided by its book value ((data25 * data199 + data181)/data6).   (market value of equity + total debt) / total assets. \n",
    "#Market value of equity is calculated as (data25 * data199). \n",
    "#Size is the logarithm of market value of equity calculated as Log(data25 * data199). \n",
    "#Book value of assets is data6 from Compustat. at\n",
    "#mtb = ((prcc_f * csho - ceq + at)/at)\n",
    "#mve = prcc_f * csho = data 199(Price – Fiscal Year – Close) * data 25(Common Shares Outstanding)\n",
    "#size = np.log(prcc_f * csho)\n",
    "\n",
    "merge['mtb'] = (merge['prcc_f'] * merge['csho'] - merge['lt'])/ merge['at']\n",
    "merge['mve'] = merge['prcc_f'] * merge['csho']\n",
    "merge['size'] = np.log(merge['prcc_f'] * merge['csho'])\n",
    "\n",
    "merge.to_csv(\"merge_v.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/w05mrsdn0r9d85szm0g3kg740000gn/T/ipykernel_27241/3841153633.py:6: DtypeWarning: Columns (34,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  segments = pd.read_csv(\"segments.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Financial complexity\n",
    "# num of BUSSEG/GEOSEG\n",
    "#count the sid by gvkey and datadate\n",
    "#NBSEG = log(number of business segments + 1)\n",
    "#NGSEG = log(number of geographic segments + 1)\n",
    "segments = pd.read_csv(\"segments.csv\")\n",
    "nbseg = segments[segments['stype'] == 'BUSSEG'].groupby(['cik', 'datadate', 'gvkey'])['sid'].count().reset_index(name='NBSEG')\n",
    "nbseg['NBSEG'] = np.log(nbseg['NBSEG'] + 1)\n",
    "ngseg = segments[segments['stype'] == 'GEOSEG'].groupby(['cik', 'datadate', 'gvkey'])['sid'].count().reset_index(name='NGSEG')\n",
    "ngseg['NGSEG'] = np.log(ngseg['NGSEG'] + 1)\n",
    "\n",
    "segments = segments.merge(nbseg, on=['cik', 'datadate', 'gvkey'], how='left')\n",
    "segments = segments.merge(ngseg, on=['cik', 'datadate', 'gvkey'], how='left')\n",
    "\n",
    "\n",
    "segments['datadate'] = pd.to_datetime(segments['datadate'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "segments = segments[['cik','datadate','gvkey','NBSEG','NGSEG']]\n",
    "segments = segments.drop_duplicates(subset=['cik', 'datadate', 'gvkey', 'NBSEG', 'NGSEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/w05mrsdn0r9d85szm0g3kg740000gn/T/ipykernel_614/254682104.py:1: DtypeWarning: Columns (44,961,983) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merge = pd.read_csv(\"merge_v.csv\")\n"
     ]
    }
   ],
   "source": [
    "merge = pd.read_csv(\"merge_v.csv\")\n",
    "merge['datadate'] = pd.to_datetime(merge['datadate'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "merge = pd.merge(merge, segments, on=['cik','datadate','gvkey'], how='left')\n",
    "merge = merge.reset_index(drop=True)\n",
    "merge.to_csv(\"merge_gh.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# 7. control variables\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenw\\AppData\\Local\\Temp\\ipykernel_20164\\1024775092.py:1: DtypeWarning: Columns (44,961,983) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merge = pd.read_csv(\"merge_gh.csv\")\n"
     ]
    }
   ],
   "source": [
    "merge = pd.read_csv(\"merge_gh.csv\") \n",
    "merge['datayear'] = pd.to_datetime(merge['datadate'], errors='coerce').dt.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firm age:\n",
    "year = pd.read_csv(\"year.csv\")\n",
    "year['year'] = pd.to_datetime(year['date'], errors='coerce').dt.strftime('%Y')\n",
    "year = year.groupby('PERMNO')['year'].min().reset_index()\n",
    "year.rename(columns={'year': 'early_year'}, inplace=True)\n",
    "year.head\n",
    "\n",
    "merge = pd.merge(merge, year, left_on=['permno'], right_on=['PERMNO'], how='left')\n",
    "merge['age'] = pd.to_numeric(merge['datayear'], errors='coerce') - pd.to_numeric(merge['early_year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special items: si = spi(data17)/at\n",
    "#DLW is a dummy that equals 1 if a company is incorporated in Delaware and 0 otherwise.\n",
    "merge['si'] = merge['spi']/merge['at']\n",
    "merge['DLW'] = (merge['incorp'] == 'DE').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RET_VOL standard deviation of the monthly stock returns in the prior year\n",
    "mon_ret = pd.read_csv(\"mon_ret.csv\")\n",
    "mon_ret['date'] = pd.to_datetime(mon_ret['date'], errors='coerce').dt.strftime('%Y-%m')\n",
    "mon_ret = mon_ret.sort_values(by=['PERMNO', 'date'])\n",
    "mon_ret['RET'] = pd.to_numeric(mon_ret['RET'], errors='coerce')\n",
    "mon_ret['RET_VOL'] = mon_ret.groupby('PERMNO')['RET'].rolling(window=12, min_periods=12).std().reset_index(level=0, drop=True)\n",
    "\n",
    "merge['ym'] = pd.to_datetime(merge['datadate'], errors='coerce').dt.strftime('%Y-%m')\n",
    "merge = pd.merge(merge, mon_ret, left_on=['permno','ym'], right_on=['PERMNO','date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility of business or operations: EARN_VOL standard deviation of the operating earnings(oiadp 178) in the last five fiscal years\n",
    "y_EARN = pd.read_csv(\"oiadp_vol.csv\")\n",
    "y_EARN = y_EARN.sort_values(by=['gvkey', 'fyear'])\n",
    "y_EARN = (y_EARN.loc[y_EARN.groupby(['gvkey', 'fyear'])['datadate'].idxmax()].reset_index(drop=True))\n",
    "y_EARN['Earnings'] = y_EARN['oiadp'] / y_EARN['at']\n",
    "y_EARN['EARN_VOL'] = y_EARN.groupby('gvkey')['Earnings'].rolling(window=5, min_periods=5).std().reset_index(level=0, drop=True)\n",
    "y_EARN = y_EARN[['gvkey','datadate','EARN_VOL']]\n",
    "\n",
    "merge['datadate'] = pd.to_datetime(merge['datadate'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "merge = pd.merge(merge, y_EARN, on=['gvkey','datadate'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NITEMS is the number of non-missing items on Compustat. \n",
    "compustat_fs = pd.read_csv(\"compustat_fs.csv\")\n",
    "compustat_fs['NITEMS'] = compustat_fs[compustat_fs.columns[9:784]].apply(lambda x: x.count(), axis=1)\n",
    "compustat_fs['datadate'] = pd.to_datetime(compustat_fs['datadate'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "compustat_fs = compustat_fs[['gvkey','datadate','NITEMS']]\n",
    "compustat_fs = compustat_fs.loc[compustat_fs.groupby(['gvkey', 'datadate'])['NITEMS'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "merge = pd.merge(merge, compustat_fs, on=['gvkey','datadate'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MA is a dummy that equals 1 if a firm appears as an acquirer in this year in SDC Platinum M&A database and 0 otherwise. \n",
    "sdc_ma = pd.read_csv(\"sdc_ma.csv\")\n",
    "sdc_ma['year'] = pd.to_datetime(sdc_ma['hdate'], errors='coerce').dt.strftime('%Y')\n",
    "sdc_ma = sdc_ma.drop_duplicates(subset=['year','ACUSIP'])\n",
    "sdc_ma = sdc_ma[['year','ACUSIP']]\n",
    "\n",
    "merge['CUSIP_6'] = merge['cusip'].str[:6]\n",
    "merge = pd.merge(merge, sdc_ma, left_on =['CUSIP_6','datayear'], right_on =['ACUSIP','year'], how='left')\n",
    "merge['MA'] = (merge['ACUSIP'].notnull()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenw\\AppData\\Local\\Temp\\ipykernel_20164\\1365115732.py:3: DtypeWarning: Columns (23,39,40,53,86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sdc_new = pd.read_csv(\"sdc_new.csv\")\n"
     ]
    }
   ],
   "source": [
    "#SEO is set to 1 for a year in which a company has a common equity offering in the secondary market according to the SDC Global New Issues database\n",
    "#seconshares:Common Stock Items: Secondary Shares (seconshares)\n",
    "sdc_new = pd.read_csv(\"sdc_new.csv\")\n",
    "sdc_new['SEO'] = (sdc_new['SECONSHARES'] > 0).astype(int)\n",
    "sdc_new['year'] = pd.to_datetime(sdc_new['MASTER_DEAL_DATE'], errors='coerce').dt.strftime('%Y')\n",
    "sdc_new['CUSIP'] = sdc_new['CUSIP'].astype(str).str[:6]\n",
    "sdc_new1 = sdc_new[['CUSIP','SEO','year']].drop_duplicates()\n",
    "sdc_new2 = sdc_new[['CUSIP9','SEO','year']].drop_duplicates()\n",
    "\n",
    "# Perform the merge operations\n",
    "merge = pd.merge(merge, sdc_new1, left_on=['CUSIP_6', 'datayear'], right_on=['CUSIP', 'year'], how='left', suffixes=('', '_sdc1'))\n",
    "merge = pd.merge(merge, sdc_new2, left_on=['CUSIP', 'datayear'], right_on=['CUSIP9', 'year'], how='left', suffixes=('', '_sdc2'))\n",
    "\n",
    "# Fill missing values in the `SEO` column\n",
    "merge['SEO'] = merge['SEO'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge[['gvkey','datadate','datayear','cik','filing_date','url','fog_index','length','num_words','mda_fog_index',\n",
    "               'mda_length','mda_words','bogindex','sic','at','Earnings','mve', 'mtb', 'size','age',\n",
    "               'NBSEG', 'NGSEG','si','RET_VOL', 'EARN_VOL','DLW', 'NITEMS','MA','SEO']]\n",
    "merge = merge.drop_duplicates()\n",
    "merge = merge.loc[merge.groupby(['gvkey','filing_date','datadate'])['age'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "merge.to_csv(\"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path:\n",
    "#segments: Segments (Non-Historical)\n",
    "#year.csv crsp_a_stock/msf\n",
    "#mon_ret.csv:crsp_a_stock/msf(Monthly Stock - Securities)\n",
    "#oiadp_vol:comp_na_daily_all/funda\n",
    "#compustat_fs:comp/comp_na_daily_all/funda\n",
    "#sdc_ma: tr_sdc_ma/wrds_ma_events\n",
    "#sdc_new: tr_sdc_ni/wrds_ni_details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
